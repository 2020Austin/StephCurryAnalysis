{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source: https://data.world/datatouille/stephen-curry-stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  36,   7, ...,   2,  14,   0],\n",
       "       [  1,  39,   5, ...,   3,  12,   0],\n",
       "       [  2,  28,   3, ...,   1,   7,   1],\n",
       "       ...,\n",
       "       [875,  33,  10, ...,   3,  29,   1],\n",
       "       [876,  36,  11, ...,   2,  35,   1],\n",
       "       [877,  25,   7, ...,   1,  23,   1]], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert tidy csv to numpy array\n",
    "filename = \"cleaned_stephcurry.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "arr = df.to_numpy()\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data and label arrays. For data, ignore index and label columns\n",
    "\n",
    "all_data = arr[:, 1 : -1]\n",
    "all_labels = arr[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-test split\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(all_data, all_labels, test_size=0.2, random_state=47)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  1  cv accuracy:  0.6425\n",
      "depth:  2  cv accuracy:  0.6481\n",
      "depth:  3  cv accuracy:  0.6653\n",
      "depth:  4  cv accuracy:  0.6610\n",
      "depth:  5  cv accuracy:  0.6239\n",
      "depth:  6  cv accuracy:  0.6310\n",
      "depth:  7  cv accuracy:  0.6140\n",
      "depth:  8  cv accuracy:  0.6382\n",
      "depth:  9  cv accuracy:  0.6425\n",
      "depth: 10  cv accuracy:  0.6254\n",
      "depth: 11  cv accuracy:  0.6340\n",
      "depth: 12  cv accuracy:  0.6325\n",
      "depth: 13  cv accuracy:  0.6239\n",
      "depth: 14  cv accuracy:  0.6211\n",
      "depth: 15  cv accuracy:  0.6240\n",
      "depth: 16  cv accuracy:  0.6340\n",
      "depth: 17  cv accuracy:  0.6382\n",
      "depth: 18  cv accuracy:  0.6254\n",
      "depth: 19  cv accuracy:  0.6268\n",
      "\n",
      "best_depth = 3 is our choice for an underfitting/overfitting balance.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "# Cross validate across parameters and find best tree depth\n",
    "\n",
    "best_d = 1\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for d in range(1,20):\n",
    "    cv_model = tree.DecisionTreeClassifier(max_depth=d)   \n",
    "    cv_scores = cross_val_score( cv_model, train_data, train_labels, cv=5 ) # 5-fold cross val\n",
    "    average_cv_accuracy = cv_scores.mean()  \n",
    "    print(f\"depth: {d:2d}  cv accuracy: {average_cv_accuracy:7.4f}\")\n",
    "    \n",
    "    if average_cv_accuracy > best_accuracy:\n",
    "        best_accuracy = average_cv_accuracy\n",
    "        best_d = d\n",
    "\n",
    "    \n",
    "    \n",
    "# assign best value of d to best_depth\n",
    "best_depth = best_d   \n",
    "print()\n",
    "print(f\"best_depth = {best_depth} is our choice for an underfitting/overfitting balance.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Gridsearch to verify our for loop results ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best parameters: {'max_depth': 3}\n",
      "Best score: 0.6653191489361703\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gs_tree = tree.DecisionTreeClassifier()\n",
    "our_gridsearch = GridSearchCV(gs_tree,\n",
    "                              param_grid={ \"max_depth\" : range(1,10)},\n",
    "                              cv=5,\n",
    "                              verbose=1,\n",
    "                              n_jobs=-1\n",
    "                              )\n",
    "\n",
    "our_gridsearch.fit(train_data, train_labels)\n",
    "\n",
    "print(f\"Best parameters: {our_gridsearch.best_params_}\")\n",
    "print(f\"Best score: {our_gridsearch.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ---- Feature importances and final accuracy! ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results: \n",
      "\n",
      "Feature importance of Minutes : 0.27628665004046493\n",
      "Feature importance of Successful Shots : 0.0\n",
      "Feature importance of Total Shots : 0.0\n",
      "Feature importance of 3 Points Succesful : 0.0\n",
      "Feature importance of Total 3 Points : 0.0\n",
      "Feature importance of Successful FT : 0.0\n",
      "Feature importance of Total FT : 0.0\n",
      "Feature importance of REB : 0.0\n",
      "Feature importance of AST : 0.08541872635911368\n",
      "Feature importance of BLK : 0.0\n",
      "Feature importance of STL : 0.0\n",
      "Feature importance of PF : 0.0\n",
      "Feature importance of TO : 0.04144598959531665\n",
      "Feature importance of PTS : 0.5968486340051048\n",
      "\n",
      "Final accuracy of our model across all data: 0.7004555808656037\n"
     ]
    }
   ],
   "source": [
    "final_tree = tree.DecisionTreeClassifier(max_depth=best_depth)\n",
    "final_tree.fit(all_data, all_labels)\n",
    "\n",
    "\n",
    "#### Create dictionary of columns for feature importance processing\n",
    "data_df = df.iloc[:, 1 : -1] #Matches data array\n",
    "\n",
    "COLUMNS = data_df.columns\n",
    "\n",
    "COLUMN_DICT = {}\n",
    "for i, name in enumerate(COLUMNS):\n",
    "    COLUMN_DICT[i] = name\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "tree_importances = final_tree.feature_importances_.tolist()\n",
    "\n",
    "print(\"Decision Tree Results: \")\n",
    "print()\n",
    "\n",
    "for i in range(len(tree_importances)):\n",
    "    print(f\"Feature importance of {COLUMN_DICT[i]} : {tree_importances[i]}\")\n",
    "    \n",
    "print()\n",
    "print(f\"Final accuracy of our model across all data: {final_tree.score(all_data, all_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  1 ntrees:  50 cv accuracy:  0.6438\n",
      "depth:  1 ntrees: 150 cv accuracy:  0.6268\n",
      "depth:  1 ntrees: 250 cv accuracy:  0.6282\n",
      "depth:  2 ntrees:  50 cv accuracy:  0.6695\n",
      "depth:  2 ntrees: 150 cv accuracy:  0.6609\n",
      "depth:  2 ntrees: 250 cv accuracy:  0.6623\n",
      "depth:  3 ntrees:  50 cv accuracy:  0.6680\n",
      "depth:  3 ntrees: 150 cv accuracy:  0.6624\n",
      "depth:  3 ntrees: 250 cv accuracy:  0.6695\n",
      "depth:  4 ntrees:  50 cv accuracy:  0.6681\n",
      "depth:  4 ntrees: 150 cv accuracy:  0.6809\n",
      "depth:  4 ntrees: 250 cv accuracy:  0.6624\n",
      "depth:  5 ntrees:  50 cv accuracy:  0.6653\n",
      "depth:  5 ntrees: 150 cv accuracy:  0.6937\n",
      "depth:  5 ntrees: 250 cv accuracy:  0.6866\n",
      "depth:  6 ntrees:  50 cv accuracy:  0.6880\n",
      "depth:  6 ntrees: 150 cv accuracy:  0.6837\n",
      "depth:  6 ntrees: 250 cv accuracy:  0.6880\n",
      "depth:  7 ntrees:  50 cv accuracy:  0.6980\n",
      "depth:  7 ntrees: 150 cv accuracy:  0.6880\n",
      "depth:  7 ntrees: 250 cv accuracy:  0.6980\n",
      "depth:  8 ntrees:  50 cv accuracy:  0.6809\n",
      "depth:  8 ntrees: 150 cv accuracy:  0.7023\n",
      "depth:  8 ntrees: 250 cv accuracy:  0.6980\n",
      "depth:  9 ntrees:  50 cv accuracy:  0.6880\n",
      "depth:  9 ntrees: 150 cv accuracy:  0.6923\n",
      "depth:  9 ntrees: 250 cv accuracy:  0.6923\n",
      "depth: 10 ntrees:  50 cv accuracy:  0.6937\n",
      "depth: 10 ntrees: 150 cv accuracy:  0.6837\n",
      "depth: 10 ntrees: 250 cv accuracy:  0.6895\n",
      "\n",
      "best_depth: 10 and best_num_trees: 250 are our choices.\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate and find best hyperparameters\n",
    "\n",
    "from sklearn import ensemble\n",
    "\n",
    "best_d = 1\n",
    "best_ntrees = 50   \n",
    "best_score = 0\n",
    "\n",
    "for d in range(1,11):\n",
    "    for ntrees in range(50,300,100):\n",
    "        rforest_model = ensemble.RandomForestClassifier(max_depth=d, \n",
    "                                                        n_estimators=ntrees,\n",
    "                                                        max_samples=0.5)\n",
    "        cv_scores = cross_val_score( rforest_model, train_data, train_labels, cv=5 ) \n",
    "        average_cv_accuracy = cv_scores.mean()  \n",
    "        print(f\"depth: {d:2d} ntrees: {ntrees:3d} cv accuracy: {average_cv_accuracy:7.4f}\")\n",
    "        if average_cv_accuracy > best_score:\n",
    "            best_d = d\n",
    "            best_ntrees = ntrees\n",
    "\n",
    "\n",
    "best_depth = best_d   \n",
    "best_num_trees = best_ntrees\n",
    "\n",
    "\n",
    "print()\n",
    "print(f\"best_depth: {best_depth} and best_num_trees: {best_num_trees} are our choices.\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Gridsearch ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best parameters: {'max_depth': 9, 'max_samples': 0.5, 'n_estimators': 250}\n",
      "Best score: 0.7037082066869301\n"
     ]
    }
   ],
   "source": [
    "gs_rf = ensemble.RandomForestClassifier()\n",
    "\n",
    "params = {\"max_depth\" : range(1, 11),\n",
    "          \"n_estimators\" : range(50, 300, 100),\n",
    "          \"max_samples\" : [0.5]}\n",
    "\n",
    "gridsearch2 = GridSearchCV(gs_rf,\n",
    "                           param_grid=params,\n",
    "                           cv=5,\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "gridsearch2.fit(train_data, train_labels)\n",
    "\n",
    "print(f\"Best parameters: {gridsearch2.best_params_}\")\n",
    "print(f\"Best score: {gridsearch2.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ---- Feature importances and final accuracy! ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results: \n",
      "\n",
      "Feature importance of Minutes : 0.27628665004046493\n",
      "Feature importance of Successful Shots : 0.0\n",
      "Feature importance of Total Shots : 0.0\n",
      "Feature importance of 3 Points Succesful : 0.0\n",
      "Feature importance of Total 3 Points : 0.0\n",
      "Feature importance of Successful FT : 0.0\n",
      "Feature importance of Total FT : 0.0\n",
      "Feature importance of REB : 0.0\n",
      "Feature importance of AST : 0.08541872635911368\n",
      "Feature importance of BLK : 0.0\n",
      "Feature importance of STL : 0.0\n",
      "Feature importance of PF : 0.0\n",
      "Feature importance of TO : 0.04144598959531665\n",
      "Feature importance of PTS : 0.5968486340051048\n",
      "\n",
      "Final accuracy of our model across all data: 0.8963553530751709\n"
     ]
    }
   ],
   "source": [
    "final_forest = ensemble.RandomForestClassifier(max_depth=best_depth, n_estimators=best_num_trees, max_samples=0.5)\n",
    "final_forest.fit(all_data, all_labels)\n",
    "\n",
    "\n",
    "forest_importances = final_forest.feature_importances_.tolist()\n",
    "\n",
    "print(\"Random Forest Results: \")\n",
    "print()\n",
    "\n",
    "for i in range(len(tree_importances)):\n",
    "    print(f\"Feature importance of {COLUMN_DICT[i]} : {tree_importances[i]}\")\n",
    "    \n",
    "print()\n",
    "print(f\"Final accuracy of our model across all data: {final_forest.score(all_data, all_labels)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data Background__: This data comes from user _Tristan Malherbe_ on __Data.World__. It's a dataset with every single NBA game played by basketball player Stephen Curry from **October of 2009 to October of 2018.** The dataset contains the following information about every game of basketball (all specific stats about Steph Curry only): \n",
    "- the date, opposing team, number of minutes Curry played, number of sucessful shots made, number of total shots attempted, number of sucessful 3 pointers, total 3-pointers attempted, sucessful free throws, total attempted free throws, rebounds, assists, blocks, steals, personal fouls, turnovers, total points scored, type of game (reg season, conference), result (win or loss), and the final team scores.\n",
    "\n",
    "Out of this, we chose to drop the date, opposing team, type of game, and final team score columns. The rest were used as features, and the result (Win or Loss) is what we were trying to predict. \n",
    "\n",
    "__Motivation__: NBA superstars like Steph Curry are often perceived as the primary drivers behind their basketball teams: if the team wins, it's because people think the superstar had a hot game and carried. If the team loses, people believe it's because the player underperformed and let the team down. We wanted to see how strongly we could predict the outcome of a basketball match by only looking at Curry's performance throughout a game. His contract is worth a LOT of money: is that money well-earned? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
